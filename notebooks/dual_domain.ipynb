{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6158d928-7f55-4326-a462-ded7c7eba7de",
   "metadata": {},
   "source": [
    "# Dual Domain Synthesis\n",
    "\n",
    "- [github](https://github.com/denabazazian/Dual-Domain-Synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f1596-d2f7-4d98-a87c-a78da3f1f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/extra/micheal/dd_synthesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111db20-5b32-4c5b-84b7-c1e6efdc5ff7",
   "metadata": {},
   "source": [
    "## Step 1. Optimize a Dual-domain Latent\n",
    "\n",
    "Here I'll optimize a latent so that it generates images similar to OCT and iOCT with respective generators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a82ba6-5355-42eb-937e-ededd8bf86f4",
   "metadata": {},
   "source": [
    "### 1. Load bscan & label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291918a6-4b3c-44e0-8606-5a3854f2021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from dataset.images_dataset import ImagesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f59047-36fd-4045-afc2-245747fdc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gap = 12 + 1 # self-defined\n",
    "gap = 255 // num_gap\n",
    "ILM = 1 * gap # present in 1, 2, 3, 4\n",
    "RNFL_o = 2 * gap # NFL/FCL in DME, present in 2\n",
    "IPL_INL = 3 * gap\n",
    "INL_OPL = 4 * gap\n",
    "OPL_o = 5 * gap # OPL/ONL in DME\n",
    "ISM_ISE = 6 * gap\n",
    "IS_OS = 7 * gap\n",
    "OS_RPE = 8 * gap\n",
    "# not sure whether they are the same\n",
    "RPE = 9 * gap\n",
    "# RPEDC = 10 * gap\n",
    "# RPE = 11 * gap\n",
    "\n",
    "BM = 10 * gap\n",
    "\n",
    "AROI_LABELS = [ILM, IPL_INL, RPE, BM] # [19, 57, 171, 190]\n",
    "FLUID_LABELS = [80, 160, 240]\n",
    "OP_LABELS = [ILM, RPE]\n",
    "aroi_map = [1, 2, 3, 4]\n",
    "op_map = [1, 3]\n",
    "fluid_map = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f0af3-7d23-4b1d-98af-ad4a8e6b1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from /home/extra/micheal/pixel2style2pixel/configs/transforms_config.py\n",
    "class Convert2Uint8(torch.nn.Module):\n",
    "    '''\n",
    "    Resize input when the target dim is not divisible by the input dim\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image or Tensor): Image to be scaled.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image or Tensor: Rescaled image.\n",
    "        \"\"\"\n",
    "        img = torch.round(torch.mul(img, 255))\n",
    "        return img\n",
    "\n",
    "class ToOneHot(torch.nn.Module):\n",
    "    '''\n",
    "    Convert input to one-hot encoding\n",
    "    '''\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Image to be scaled of shape (1, h, w).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Rescaled image.\n",
    "        \"\"\"\n",
    "        img = img.long()[0]\n",
    "        img = torch.nn.functional.one_hot(img, num_classes=self.num_classes)\n",
    "        img = img.permute(2, 0, 1)\n",
    "        return img\n",
    "    \n",
    "class MapVal(torch.nn.Module):\n",
    "    '''\n",
    "    Map a list of value to another\n",
    "    '''\n",
    "    def __init__(self, src_vals, dst_vals):\n",
    "        super().__init__()\n",
    "        assert len(src_vals) == len(dst_vals), \"src_vals and dst_vals must of equal length\"\n",
    "        self.src_vals = src_vals\n",
    "        self.dst_vals = dst_vals\n",
    "    \n",
    "    def forward(self, img):\n",
    "        for s, d in zip(self.src_vals, self.dst_vals):\n",
    "            img[img==s] = d\n",
    "        return img\n",
    "\n",
    "def get_transforms(opts):\n",
    "    transforms_dict = {\n",
    "        'transform_gt_train': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5] * opts.output_nc, [0.5] * opts.output_nc)]),\n",
    "        'transform_source': transforms.Compose([\n",
    "            transforms.Resize((256, 256), interpolation=InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            Convert2Uint8(),\n",
    "            MapVal(opts.src_vals, opts.dst_vals),\n",
    "            ToOneHot(opts.label_nc)\n",
    "            ])\n",
    "    }\n",
    "    return transforms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251543b-ddc0-48dd-bbd2-19f310c1279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aroi_bscan_root = \"/home/extra/micheal/IDP/data/splits/AROI/original/bscans/train\"\n",
    "aroi_label_root = \"/home/extra/micheal/IDP/data/splits/AROI/original/labels/train\"\n",
    "aroi_opts = Namespace(output_nc=1, label_nc=7, src_vals=AROI_LABELS+FLUID_LABELS, dst_vals=aroi_map+fluid_map)\n",
    "transform_dict = get_transforms(aroi_opts)\n",
    "aroi_dataset = ImagesDataset(source_root=aroi_label_root,\n",
    "                            target_root=aroi_bscan_root,\n",
    "                            source_transform=transform_dict['transform_source'],\n",
    "                            target_transform=transform_dict['transform_gt_train'],\n",
    "                            opts=aroi_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0bb02-35be-41ef-89ee-8cc6bc1467e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/home/extra/micheal/IDP/data/splits/AROI/original/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dae663-79a9-488c-9b9f-a25d25938c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aroi_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cfcff-1259-4212-b815-f76ae24b07ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
