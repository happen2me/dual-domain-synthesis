{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc37d2e-1a9f-4ae0-a104-c1524e05980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/extra/micheal/dd_synthesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0b220-e244-4b1f-b7fe-cb0ad62d6ccd",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e00b6a-46ac-4cb6-a20e-5cfb8b32932e",
   "metadata": {},
   "source": [
    "The goal of the segmentation network in DD Synthesis paper is to identify the face mask of both source and the target domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f16d81-ae52-4398-927d-f5f778ea54cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform the Line Segmentation to Area Segmentation\n",
    "\n",
    "The first chanllenge is that, using the original approach, we need to find out the \"mask\" of the feature to be integrated. In the OCT datasets, the segmentations are given as line layers. We have to transform the lines to area masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8c302-e1db-4bca-b9c8-5840d16e20cc",
   "metadata": {},
   "source": [
    "### 1. Visualize the Current Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58df098-eda3-4002-a8e7-f8098c4fc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_segmentation(bscan, label, show_original=False, alpha=0.8):\n",
    "    color_map = {\n",
    "        1: 'white',\n",
    "        2: 'red',\n",
    "        3: 'gray',\n",
    "        4: 'orange',\n",
    "        6: 'gainsboro'\n",
    "    }\n",
    "    if show_original:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(5, 10))\n",
    "        axs[0].imshow(bscan)\n",
    "        axs[0].axis('off')\n",
    "        axs[0].set_title('original')\n",
    "        axs[1].set_title('segmentation')\n",
    "        draw_handle = axs[1]\n",
    "    else:\n",
    "        draw_handle = plt\n",
    "    draw_handle.axis('off')\n",
    "    draw_handle.imshow(bscan)\n",
    "    for k, color in color_map.items():\n",
    "        x, y = np.where(label==k)\n",
    "        draw_handle.scatter(y, x, color=color, alpha=alpha, linewidths=0, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e2a25-4a61-4097-a12b-6074b5544668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bscan_label(img_name, bscan_prefix=\"data/ioct/bscans/val/\", label_prefix=\"data/ioct/labels/val/\"):\n",
    "    bscan = Image.open(bscan_prefix + img_name)\n",
    "    label = np.asarray(Image.open(label_prefix + img_name))\n",
    "    return bscan, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfceb66a-5b24-4fcb-a411-31bcac27ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bscan_prefix = \"data/ioct/bscans/val/\"\n",
    "label_prefix = \"data/ioct/labels/val/\"\n",
    "img_name = \"5d396575-e039-49da-a219-fe239e8bd9c88062-101.png\"\n",
    "\n",
    "bscan, label = get_bscan_label(img_name, bscan_prefix, label_prefix)\n",
    "visualize_segmentation(bscan, label, show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3950b59-a8e5-4e3e-8789-a670536a280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"OS-2020-02-03_114037fs-039.png\"\n",
    "bscan, label = get_bscan_label(img_name)\n",
    "visualize_segmentation(bscan, label, show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ed098-b57d-4c7f-9751-00482f3e810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"OS-2020-02-03_135535fs-089.png\"\n",
    "bscan, label = get_bscan_label(img_name)\n",
    "visualize_segmentation(bscan, label, show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e8b45-f430-4f3c-bffa-cb30eb8f613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shadow(label):\n",
    "    shadow_x = np.array([], dtype=np.int64)\n",
    "    shadow_y = np.array([], dtype=np.int64)\n",
    "    # Requirements for the shadow label:\n",
    "    # 1. Horizontally after the starting of the instrument/mirroring & before the\n",
    "    #    ending of the instrument/mirroring\n",
    "    # 2. Vertically below the (upperbound of) label 1\n",
    "    x, y = np.where(np.logical_or(label==2, label==4)) # (1024, 512)\n",
    "    if len(x) == 0:\n",
    "        return shadow_x, shadow_y\n",
    "    left_bound = np.min(y)\n",
    "    right_bound = np.max(y)\n",
    "    x, y = np.where(label==1)\n",
    "    upper_bound = np.min(x)\n",
    "    left_end = upper_bound\n",
    "    right_end = upper_bound\n",
    "    for i in (left_bound, 0, -1):\n",
    "        left_1 = np.where(label[:, i]==1)[0]\n",
    "        if len(left_1) > 0:\n",
    "            left_end = left_1[0]\n",
    "            break\n",
    "    for i in range(right_bound, 512):\n",
    "        right_1 = np.where(label[:, i]==1)[0]\n",
    "        if len(right_1) > 0:\n",
    "            right_end = right_1[0]\n",
    "            break\n",
    "    upper_bound = max(upper_bound, min(left_end, right_end))\n",
    "    for i in range(left_bound, right_bound):\n",
    "        x_vertical = np.arange(upper_bound, 1024) # upperbound to bottom\n",
    "        y_vertical = np.full_like(x_vertical, i)\n",
    "        shadow_x = np.concatenate([shadow_x, x_vertical])\n",
    "        shadow_y = np.concatenate([shadow_y, y_vertical])\n",
    "    return shadow_x, shadow_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c40f6-a08f-49fa-bc31-d8fe0b645262",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_shadow(label)\n",
    "label_copy = label.copy()\n",
    "label_copy[x, y] = 6\n",
    "visualize_segmentation(bscan, expand_label(label_copy), show_original=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb2050-bd9f-4696-84ad-69428591b1c7",
   "metadata": {},
   "source": [
    "### 2. Expand Label to Cover the Whole Area\n",
    "\n",
    "By observing the bscans, we found out we need to:\n",
    "1. Expand instrument & mirroring labels horizontally\n",
    "2. Invent a new shadow label which reside below the instruments and mirroring.\n",
    "\n",
    "Note: for the shadow label, we don't really wish it to resembel the target domain (iOCT). We wish it to keep the noise texture of the original OCT domain, but leaves blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f30d16-13ec-468f-9994-199b88ef0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    1: 'white',\n",
    "    2: 'red',\n",
    "    3: 'gray',\n",
    "    4: 'orange',\n",
    "    6: 'gainsboro'\n",
    "}\n",
    "\n",
    "def horizontal_expand(label, feature, to_expand=20):\n",
    "    label_copy = label.copy()\n",
    "    x, y = np.where(label_copy==feature)\n",
    "    xacc, yacc = x, y\n",
    "    for i in range(to_expand):\n",
    "        xacc = np.concatenate([xacc, x])\n",
    "        yacc = np.concatenate([yacc, y+i])\n",
    "    label_copy[xacc, yacc] = feature\n",
    "    return label_copy\n",
    "\n",
    "def expand_label(label, expansion2=30, expansion4=60):\n",
    "    # For label 2 4 (instrument & its mirroring), we horizontally expand\n",
    "    # a couple of pixels rightward\n",
    "    label = horizontal_expand(label, 2, to_expand=expansion2)\n",
    "    label = horizontal_expand(label, 4, to_expand=expansion4) # shadows are generally broader\n",
    "    return label\n",
    "\n",
    "img_name = \"OS-2020-02-03_114037fs-039.png\"\n",
    "bscan, label = get_bscan_label(img_name)\n",
    "visualize_segmentation(bscan, expand_label(label), show_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea674b8-751c-49b1-8fc3-28dbf9cd568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_shadow(label)\n",
    "label_copy = label.copy()\n",
    "label_copy[x, y] = 6\n",
    "visualize_segmentation(bscan, expand_label(label_copy), show_original=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c81725-90b6-425f-b1f3-b4cab3677845",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train a Segmentation Network\n",
    "\n",
    "The strategy is to stick to the original labels for classification. After we get the segmentation as lines, we expand it to area masks using the methods above.\n",
    "\n",
    "The original paper use a repurpose GAN as segmentation network with one-shot learning. But I don't see the advantage of using it over a plain segmenter. (Or probably the paper explained it? **#CHECK**)\n",
    "\n",
    "Here I use a simple U-Net structure as the segmentation network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deecc2d-9163-4191-baa2-e30453907842",
   "metadata": {},
   "source": [
    "### Update: Seems No Need\n",
    "\n",
    "The masks are given as ground truth, maybe we don't have to train a new segmentor for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29f729-ddb3-495e-ac22-6eeea69e3896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
